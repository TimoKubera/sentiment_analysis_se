{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description and Explorative Data Analysis\n",
    "Novielli et al. [1] created a gold standard data set from GitHub data, which includes 7122 data points in total.\n",
    "Each data point contains a ID column, a text column and a column, containing one of the three polarity classes („neutral“, „positive“, „negative“).\n",
    "The data points were labeled by 3 independent raters, for the most part, using the Shaver et al. [2] emotion framework.<br>\n",
    "Eventually the polarity classess „positive“, or „negative“ were assigned to the data points, respectively „neutral“, if neither „positive“ or „negative“ was assigned.<br>\n",
    "The dataset is fairly well balanced, with 29% negative labels, 28 % positive labels and 43 % neutral labels.<br>\n",
    "It’s worth mentioning that natural text, especially in the software engineering jargon, is more often absent from sentiment, than it expresses sentiment.\n",
    "Therefore a truly even distribution of the polarity clases (33% positive, 33 % neutral, 33% negative), would probably not be beneficial.<br>\n",
    "The GitHub dataset was created using an iterative approach:<br>\n",
    "1. From a GitHub dataset of 116k documents, 4k documents were randomly selected and manually annotated by three raters.\n",
    "They decided by majority which polarity class should be assigned to which document.\n",
    "Duplicates and documents for which the raters could not assign a polarity class by majority vote were removed, adding 3931 documents to the gold standard data set.\n",
    "2. Since there was an excess of neutral comments (77%), more positive and negative documents should be added to the dataset.\n",
    "To save time, the Senti4SD classifier was trained with the approx. 4k documents from the first step in order to automatically classify the remaining 112k documents.\n",
    "From this, 600 positively and 600 negatively evaluated documents were selected at random and the majority of the evaluators had to agree on whether they agreed with the classification of Senti4SD or not. Ultimately, 343 more positive and 550 negative comments were added to the gold standard dataset.\n",
    "3. In the third step, the classifier was trained again, this time with the data set obtained from step 2..\n",
    "With the same procedure as in step 2., another 1124 positively classified documents and 1204 negatively classified documents could be added to the gold standard dataset.\n",
    "The result is a gold standard data set with 7122 comments. The iterative approach is also appended in graphic 1.\n",
    "\n",
    "The data is imported and some core statistics are printed and visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7122, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f_path = os.path.abspath('')\n",
    "data = pd.read_csv(os.path.join(f_path, 'data/github_gold.csv'), delimiter=';')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a redundant 'ID' column as well as a polarity and a text column. Let's get rid of the id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>No. I still see the wrong twins.  * https://gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Reverted.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>You can leave a queue while in queue ? (before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Didn't look at SpellTargetRestrictions XD\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Not sure about what kind of line lengths the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "      <td>@normanmaurer Nice catch ! Did you make the sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neutral</td>\n",
       "      <td>That's why I didn't close after sending the cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Build result for 78d8f05c218cab107255c4dc1a134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why you think using ImmediateEventExecutor is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neutral</td>\n",
       "      <td>These are the ones we currently hardcode in Te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polarity                                               Text\n",
       "0   neutral  No. I still see the wrong twins.  * https://gi...\n",
       "1   neutral                                         Reverted.\"\n",
       "2   neutral  You can leave a queue while in queue ? (before...\n",
       "3  positive         Didn't look at SpellTargetRestrictions XD\"\n",
       "4   neutral  Not sure about what kind of line lengths the p...\n",
       "5  positive  @normanmaurer Nice catch ! Did you make the sa...\n",
       "6   neutral  That's why I didn't close after sending the cl...\n",
       "7   neutral  Build result for 78d8f05c218cab107255c4dc1a134...\n",
       "8   neutral  Why you think using ImmediateEventExecutor is ...\n",
       "9   neutral  These are the ones we currently hardcode in Te..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns='ID', inplace=True)\n",
    "data.head(n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization of the distribution of the polarity classes is follwing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/49sqz_0968dgz95nxsm709yw0000gn/T/ipykernel_5319/1334325380.py:3: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-paper')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAGiCAYAAAAIvKc3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+HklEQVR4nO3deXwN9/7H8feJQ0KTk5AgIZuIRK2xL21tRYsqtVxqDVW0t4tStXSjC9W66HZvtVUpWtVbrarSohfl0pYSWkrElhBBJLIQkWV+f7jOT0pWSU+Y1/PxOI9m5vud73wmGcm7M98zx2IYhiEAAACTcHJ0AQAAAH8lwg8AADAVwg8AADAVwg8AADAVwg8AADAVwg8AADAVwg8AADAVwg8AADAVwg8AADAVwg9QwmbMmKGuXbuW+Lj169fXxx9/LEk6evSoLBaLoqOjS3w/3bp108svv1zi4xZFZmamBg8erCpVqsjV1VXJycmF2m7jxo2yWCzKysoq5QqLZtq0abrzzjtveJyrz4G/Qln9fgI3ivADFFKHDh1UoUIFubm5yd3dXX5+furdu7e+/fbbXP2mTp2qtWvXFmrMwMBAffjhh4Xqu3fvXg0fPrzIdeclrwC1Zs0aPf/88yW2n+L44osvtGHDBh09elRpaWlyd3e/pk94eLiGDBnigOoc5+pzoDQDMHCrI/wARfDMM88oNTVVycnJ+vXXX9W1a1cNHDhQzz77bKnt89KlS6U2dll16NAhBQUFyWazObqUMsGM5wBQmgg/QDFVq1ZNjz76qObNm6fXXnvN/n/gf77F8c4776h27dpyc3NT9erVFR4eLuny7aWYmBg99thjcnV1Vf369XNt//zzz6tGjRoKCwuTdP2rRBs2bFC9evVks9l0991369ChQ/a2Dh066LnnnsvV/+oxruyvcePGcnV11dixY6+73R9//KFu3brJy8tLvr6+GjNmTK7bUB06dNCTTz6pQYMG2a+I/etf/8r3e5ffmOHh4XrppZe0bds2ubq6qlu3btdsP2PGDH3yySdatmyZXF1d5erqqpiYGHv7ihUrFBISIjc3N3Xp0kUnTpywt128eFFTp05V7dq1VblyZbVr1067du3Ks9Yrt34++eQTBQUFycPDQw888IBOnz5t73Pu3DmNHj1avr6+8vLyUrdu3XTgwIE8x3z33XfVoEED2Ww2eXt7a+jQoUpISLC3F+YcuN7Pb8GCBapdu7au/rzqjIwMeXl5acWKFdetJSsrS3PmzFG9evXk5uYmX19fzZo1K8/vRdu2beXp6anKlSurU6dOioyMtLfHxMSoe/fuqlKlitzd3dWgQQNt3rxZkrR79261b99eHh4eqly5spo1a5bre7Ro0SI1btxY7u7uql+/vj777LNCjQsUB+EHuEGDBg2SJP3www/XtB08eFDPPPOMvv76a6WmpurQoUMaOXKkpMu3l/z9/fXOO+8oLS1Ne/futW/3008/qXz58jp8+LB27NiR574/+OADff/994qPj1etWrXUs2fPQs/PuLK/3bt3Ky0tTe+99941fVJTU9W5c2fVq1dPMTEx2r59u/bv33/N7beIiAiNGjVKSUlJmjdvnh577LE8b8cUNGZERISmTp2qNm3aKC0tTWvWrLlmjKlTp2rw4MEaMGCA0tLSlJaWJn9/f3v7V199pe3bt+v48eO6cOGCpk6dam8bO3asfvnlF23atElnzpzR3/72N91zzz06d+5cvt+vpUuXaseOHTpy5IguXbqU65bb0KFDdfDgQe3YsUMxMTEKDQ1V586dlZaWdt2xvL299eWXX+rcuXP6+eefFRUVpccffzxXn4LOgev9/B588EGdPXtW69evt/f74osv5OLiop49e163lmnTpumf//ynIiIilJycrD179qhdu3bX7Vu+fHnNnj1bJ0+eVExMjIKDg9WrVy/7lakpU6aoZs2aiouLU1JSkpYvXy5fX19J0qOPPqq7775bCQkJOnPmjBYsWCAPDw9Jl3/mzz33nBYsWKCkpCTNnz9fo0eP1pYtWwocFygOwg9wgypWrCgvLy+dPXv2mjar1SrDMLR3716lpKTI1dU1zz8sV6tevbqef/55ubi4qFKlSnn2e/755+Xn56dKlSpp7ty5ioqK0rZt227oeK62atUqXbp0SbNmzVKlSpXk4+OjefPm6euvv1Z8fLy9X9++fdWpUyc5OTmpb9++qlKlin799dcbGvNGzJw5U+7u7nJ3d9egQYP0yy+/SJLOnj2rjz/+WO+++658fX1ltVr12GOPyd3dXatWrSpwzCpVqqhy5cqaPXu21q1bp9jYWJ08eVKrVq3SvHnz5O3trUqVKumNN95Qenp6nmP27dtXISEhcnJyUkBAgCZPnnzNPLHCngNXq1SpkoYPH67333/fvm7+/PkaNWqUypUrd01/wzD05ptv6rXXXlPLli3l5OSkKlWqqE2bNtcd/4477lDbtm3tc99mzZqlmJgY+xWcChUqKD4+XocOHZLFYlFoaKhq1aplb4uJidGxY8dktVoVFham6tWrS5LmzJmjZ599Vs2bN5eTk5PuvPNODRgwQBEREQWOCxQH4Qe4Qenp6Tpz5ow8PT2vaatVq5Y+++wzLVy4UP7+/mrRooWWLl1a4JgBAQGyWCwF9rv6D4Cbm5u8vLwUGxtbtAPIR2xsrAICAmS1Wu3rgoODJSnXbaYaNWrk2u62225TamrqDY15I66u5+parlyNatWqlTw8POyvEydO6Pjx4/mOefX3+srXsbGx9u937dq17e3ly5dXQEBAnsfz5Zdfqm3btqpWrZpsNpuGDh2qxMREZWdn2/sU9hz4s0ceeUQrV67UqVOn9Mcff2jr1q0aNWrUdfsmJCQoLS1NoaGhhRp7z5496tmzp2rWrCmbzWb/Ply5BTh79mwFBwerT58+ql69ukaMGKFTp05Junx1x2KxqFOnTvL19dW4cePsV8YOHjyoCRMm5PqZLF26VHFxcQWOCxQH4Qe4QUuXLrX/Ur+eXr166bvvvlNCQoImTpyowYMHKyoqSpLk5HT9f4J5rf+zo0eP2r9OS0tTQkKC/XaAm5ubzp8/b2/PysrKNU+lMPvw8/NTTExMrltpV+YVXX2bqShKaszCfo+u5u3tLenyH/Fz587ZXxcuXNDkyZPz3fbq7/WVr319feXn5ydJueZbZWVlKSYm5rrHc/z4cfXv31+PP/64YmJilJKSosWLF0tSrrk6BR1fXu1169bVHXfcoYULF2r+/Pnq0aNHnreIvLy85Orqaj8fC9K/f3/Vrl1bv//+u1JSUnTkyJFcdXt6emru3Lk6cOCAdu3apaNHj2r8+PGSLoe5Dz74QMeOHdPGjRu1bt06zZw5U9Lln8s///nPXD+TtLQ0rV69usBxgeIg/ADFdObMGc2fP1/jxo3TxIkTVadOnWv6HDhwQKtXr1ZaWpqsVqv9LdtXbkF4e3vnOzG2IK+88op9XsuECRMUHBystm3bSpKaN2+ulStXKi4uTunp6Zo8ebIyMzPt21atWlVOTk757r9Hjx6yWq2aOnWq0tPTFR8fr6eeeko9e/a0B4miKqkxvb29dejQoVxXSwoSEBCg3r176+9//7uOHTsm6fIcpDVr1ujkyZP5bjt16lQlJibq3Llzmjhxojp16iR/f3/5+Pioe/fumjBhgk6dOqX09HRNmjRJFSpUUI8ePa4ZJy0tTTk5OfLy8pKLi4sOHjxoDwFFkd/P79FHH9X777+vRYsWacyYMXmOYbFY9Pjjj2vKlCnasWOHDMNQYmJinrdOk5OTZbPZ5O7ursTERE2YMCFX+2effaZDhw4pJydHbm5ucnZ2tl/hi4iI0PHjx2UYhmw2m6xWq71t3Lhxevnll7V9+3bl5OQoIyND27dvt986zW9coDgIP0ARvP7663J1dZXNZlOTJk20evVqLVmyRK+99tp1+1+6dEmvvvqq/TbBhAkTtGjRIvstkhdeeEFff/21PDw81KhRoyLX89BDD6lLly6qXr26oqKi9M0339j/KDz11FNq1qyZbr/9doWGhio4OFg1a9a0b1uxYkXNmDFDo0aNkoeHhx599NFrxrfZbFq3bp12794tX19fNWvWTMHBwTf0oL2SGnP06NGSLl+98PDwKPQts08//VTNmjVTly5d5ObmptDQUH3wwQe5rrpcz4ABA9S8eXMFBATIyclJn3zyib1t8eLFCgwMVNOmTeXr66u9e/dq/fr1cnNzu2acunXraubMmRo2bJjc3Nw0fPjwYj2vKL+fX+/evXXx4kXZbDbde++9+Y7z0ksvadSoURo8eLDc3NzUqFGjPN9J9dFHH+nf//633Nzc1Lp162veibd792516tRJbm5uql27tjw8PDR79mxJl9+Z2LJlS7m6uqpx48Zq06aNJk2aJEl68sknNW3aNI0dO1ZVqlRRzZo1NXHiRPuVy/zGBYrDYhT0Lx4ATGzjxo3q2LGjMjMzb6qrDa1atdL9999fqs+gAm5WN8+/ZABAoaxevVq///77NU8fB3AZ4QcAbiF+fn5KT0/Xe++9Jy8vL0eXA5RJ3PYCAACmwoRnAABgKoQfAABgKoQfAABgKkx4/pOcnBzFxcXJzc2tWI+WBwAAfz3DMJSamqoaNWoU+IR0ws+fxMXF2R9XDwAAbi6xsbF5fqTLFYSfP7nyRNbY2FjZbDYHVwMAAAojJSVFfn5+132y+p8Rfv7kyq0um81G+AEA4CZTmCkrTHgGAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACm4rAPNu3atavi4+Pl5OQkNzc3vfXWW2rSpIkOHjyo4cOHKyEhQe7u7oqIiFD9+vUlqdhtAC7LysrS4cOHHV0GHCwoKEhWK59rDfNy2Nn/+eefy8PDQ5L01VdfKTw8XLt379aYMWM0evRohYeH64svvlB4eLi2b98uScVuA3DZ4cOHFRm5Sb6+Po4uBQ5y/PhJSVJISIiDKwEcx2IYhuHoIiIiIjRv3jytXbtWwcHBSkxMlNVqlWEY8vHx0ZYtW2Sz2YrVFhwcnO++MzIylJGRYV9OSUmRn5+fkpOTZbPZSvvQgb9UVFSUEhKiFFTb39GlwEEOH4qRl1cI4Qe3nJSUFLm7uxfq77dDr3sOGzZMGzZskCStXr1asbGx8vHxsV+OtVgs8vf3V0xMjNzd3YvVVlD4mTlzpqZPn16KRwkAAMoSh054XrRokWJjY/XKK69o0qRJDqlhypQpSk5Otr9iY2MdUgcAAPhrlIkZb8OHD9fYsWPl6+urkydPKisry377KiYmRv7+/rLZbMVqK4izs7OcnZ3/gqMEAABlgUOu/Jw7d05xcXH25RUrVsjT01PVqlVT06ZNtWTJEknS8uXL5evrq+Dg4GK3AQAAXM0hV36Sk5PVv39/paeny8nJSVWrVtWqVatksVg0f/58hYeHa8aMGbLZbFq4cKF9u+K2AQAAXFEm3u1VlhRltjhws+HdXuDdXrhVFeXvN094BgAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AVCmvf32Avl4N9bzz79uX5eUlKxnp87UnXfcr1qBLdWs2T167tnXlJKSWuhxn3nmZfl4N9b77y/Jt9/y5d+qWdOuqht6p1588Y1cbbExJ3RH255KTU0r2kEBcCirowsAgLxE7vpdixd9oXr1QnKtPxV/WvGnzuiFF8crJKS2jh+P06RnXlF8/Bl9uOAfBY67evUP2vnrb/L2rppvv7Nnk/T0hOmaN+8lBQT4asiQx3TnHS3VpWt7SdLkyTM09dkn5ebmWvyDBPCX48oPgDLp/PkL+vvfp2j2P16Uu7stV1vd2+towYI56tq1gwID/XTnna00efLjWrduk7KysvId9+TJU3ru2df07rszZLWWz7dvzLHjcnNzVa/e9yqsSQPdcUcLHTx4RJL01VdrVL68VT16dL6xAwXwlyP8ACiTpkyeobs7t1O7dq0L1T8lNU2urq6yWvO+oJ2Tk6PHH3tWjzwartC6wQWOWSsoQOnpF/Xbb38oKSlZkZF7dXu9Ojp3LkWvz3pXr86YUujjAVB2cNsLQJmzYsUa/fbbH1rz3aeF6n/2bJLmznlfQ4b2zbffO+8sVDlrOY0aNahQ43p42PTmWy/ricef08WLGerfv6c6drxD4596USNGDlRMzAmFD39CmZlZevrpR3Rfzy6FGheAYxF+AJQpJ07E6/nnXteyz+fLxcW5wP6pqWkaOuQxhYQE6emnx+bZb/fuffrwg0+0dt1nslgsha6ne/e71b373fblrVt3aN++g3rl1clq26an/vmv11Stmpe6dxus1q2byquqZ6HHBuAYDrntdfHiRfXu3VshISFq3LixunTpoujoaElShw4dVKtWLYWFhSksLExz5861b3f69Gnde++9qlOnjho0aKAff/yxUG0Abh579uxTQkKiunYZKN+aTeVbs6m2bduhBR9+Kt+aTZWdnW3vm5Z2XoMefFSurrfpo4VzVb583nN4fv55pxISEtW82b32cY8fj9P0af9Qi+bdClVbRsYlTZn8ql5/43kdPRqrrKwstW3bXMHBgQoKCtDOXb/d8PEDKH0Ou/IzevRodevWTRaLRe+8845GjRqljRs3SpLmzp2r3r17X7PN5MmT1bp1a3333Xfavn27HnjgAR05ckTly5fPtw3AzeOuu1ppw4Yvcq0bN+5FBdcJ1GN/H6Fy5cpJunzF58GBj6hChQqK+PjNAq8S9et3n9rd1SrXugcffET9+t2nAQN7F6q2efPeV8eOd6hRo9v1229/5ApiWVlZys7OKdQ4ABzLIeHHxcVF3bt3ty+3bt1as2fPLnC7zz//3H6FqEWLFqpRo4Y2bdqkzp0759sG4Obh6nqb6t5eJ9e6SpUqqnJlD/v61NQ0DRwwVunpF/XOuzOUlnZeaWnnJUmenpXtAenOO3tp6tQn1L373apSxUNVqnjkGtdqLa+q1bwUHBxYYF0HDhzSyq+/17p1yyRJwcG1ZHFy0qeffqlqVb0UHX1EYWH1b/DoAfwVysScnzfffFO9evWyL0+ePFnPP/+86tWrp5kzZyooKEhnz55VZmamvL297f0CAwMVExOTb1tBMjIylJGRYV9OSUkpoaMCUFp+2/OHdu68fIupTev7crX98stq+fnXlCQdij6q1JQbfwChYRiaOPElTZv2tCrdVkmSVLGii96c95KmTJmpS5cu6dUZU+TjU/2G9wWg9Dk8/MyYMUPR0dH64YcfJEmLFy+Wn5+fDMPQu+++q/vuu0/79u0rtf3PnDlT06dPL7XxAdy4L79akGu57R0tdDJ+d4HbFdRn+441hdq/xWLRypUfX7O+S9f29gceArh5OPQ5P7Nnz9aXX36pNWvWqFKly/835efnJ+nyL5vHHntMhw8f1tmzZ+Xp6Smr1ar4+Hj79kePHpW/v3++bQWZMmWKkpOT7a/Y2NgSPkoAAFCWOCz8zJkzR0uXLtW6devk4eEh6fKEwVOnTtn7LF++XNWrV5en5+W3jvbv31/vvfeeJGn79u06ceKE2rdvX2BbfpydnWWz2XK9AADArcsht72OHz+uCRMmKCgoSB07dpR0OYT85z//UY8ePZSRkSEnJyd5eXlp5cqV9u1mzZqloUOHqk6dOqpQoYKWLFlifzdXfm0AAABXOCT8+Pr6yjCM67bt2LEjz+2qV6+utWvXFrkNAADgCj7bCwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmIrV0QWYSVZWlg4fPuzoMuBgQUFBslr5pwcAjsJv4L/Q4cOHFT1hsgIqVnJ0KXCQY+kXpH+8ppCQEEeXAgCmRfj5iwVUrKQ6rq6OLgMAANNizg8AADAVwg8AADAVwg8AADAVwg8AADAVh4Sfixcvqnfv3goJCVHjxo3VpUsXRUdHS5JOnz6te++9V3Xq1FGDBg30448/2rcrbhsAAMAVDnu31+jRo9WtWzdZLBa98847GjVqlDZu3KjJkyerdevW+u6777R9+3Y98MADOnLkiMqXL1/sNgBA2cDzziA5/nlnDtmzi4uLunfvbl9u3bq1Zs+eLUn6/PPP7VeBWrRooRo1amjTpk3q3Llzsdvyk5GRoYyMDPtySkpKiR4rAOD/HT58WH1emqZybjzyw6yyU9P05QvTHPq8szLxnJ8333xTvXr10tmzZ5WZmSlvb297W2BgoGJiYordVpCZM2dq+vTpJXtAAIA8lXNzVTl3m6PLgIk5fMLzjBkzFB0drZkzZzpk/1OmTFFycrL9FRsb65A6AADAX8Oh4Wf27Nn68ssvtWbNGlWqVEmenp6yWq2Kj4+39zl69Kj8/f2L3VYQZ2dn2Wy2XC8AAHDrclj4mTNnjpYuXap169bJw8PDvr5///567733JEnbt2/XiRMn1L59+xtqAwAAuMIhc36OHz+uCRMmKCgoSB07dpR0+QrMzz//rFmzZmno0KGqU6eOKlSooCVLltjfsVXcNgAAgCscEn58fX1lGMZ126pXr661a9eWaBsAAMAVDp/wDAAA8Fci/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMpVviZM2eOzpw5U9K1AAAAlLpihZ/169crICBAPXv21BdffKHMzMySrgsAAKBUFCv8rF69WkeOHFHHjh31yiuvyNvbW3//+9+1ffv2kq4PAACgRBV7zk/16tU1fvx4RUZGat26dfrvf/+r1q1b6/bbb9dbb72lS5culWSdAAAAJeKGJjxHRkZq/Pjx6tGjh8qVK6c333xTr7/+ulatWqWePXuWVI0AAAAlxlqcjd544w0tXrxYp06d0qBBg/T999+rUaNG9vYuXbrIy8urxIoEAAAoKcUKP5s3b9b06dPVs2dPWa3XDuHi4qKVK1fecHEAAAAlrVi3ve6//3498MAD1wSfBQsW2L/u1KnTjVUGAABQCooVfsaPH3/d9RMnTryhYgAAAEpbkW57RUVFSZJycnJ08OBBGYZhbzt06JBcXFxKtjoAAIASVqTwU7duXVksFklSaGhorjZvb29Nnz695CoDAAAoBUUKPzk5OZKkO+64Q//9739LpSAAAIDSVKw5PwQfAABwsyr0lZ/OnTtr/fr1kqQ2bdrYb3/92datW0umMgAAgFJQ6PAzcuRI+9djx44tlWIAAABKW6HDz6BBg+xft27d+poJz5J04MCBkqkKAACglBRrzk+LFi2uu75NmzY3VAwAAEBpK1b4ufr5PlecO3dOTk439DmpAAAApa5Ib3X38fGRxWJRenq6atSokastKSlJQ4YMKdHiAAAASlqRws9nn30mwzDUvXt3LV261L7eYrGoevXq150HBAAAUJYUKfy0b99ekhQfHy+bzVYqBQEAAJSmIoWfKypVqqSIiAjt3LlTaWlpudo++uijEikMAACgNBQr/IwYMULbtm1Tjx49VL169ZKuCQAAoNQUK/ysWrVKBw8elJeXV0nXAwAAUKqKFX68vb1ltRZrU9wEXt+zSyuOHdGBc+dU0VpOrat569XmrRTq7mHvcyglWZO3/6Stp+KVkZOtrjX9NLf1HapesVKe487fv1fv79+nY2mpkqR6HpU1NayZ7vX1z3Ob9SeO68mftuhU+gX19A/U/Dvaq0K5cpKk5EsZavvNV1p9Tw8FuLqVzMEDgKT4bT8rOeqgLiYmyslq1W01a6hG+3Zy8axi75OZdl4nNm5S6tFjyrl0Sc5Vqsi7TSt5hIbkOe6ZXZFK2LVbl5JTJEkuXp7ybttG7rVr5blNypGjOr7uP8o8f17udWrLv9s9cvrf78HsjAwd+PgTBQ/opwruzMUtrGI9mGf8+PEaOHCgNm/erKioqFwv3Px+jI/T2Lr1tfm+3lp9z33KzMnRfd9/q/OZmZKk85mZ6rF2tSySvr/3Pm3s3kuXcnLUZ/13yrnOM6CuqFnpNr3SrJW29eyrrT37qINPTfX74XvtS0q8bv8cw9DwTT/o4dB6+rFHb/2acEYfHvjD3v7sjl/0cGg9gg+AEpcWe1xeTcMUMmSQag/oJyM7R9Gff6HsS5n2Pse+XaOMxCQF9emtuiOHyyOkjo58vUoXTp3Kc9wKbm6q0f4uhQ4fotDhg+UW4K8jX65Q+pmE6/Y3DEPHvlktr7BGChnyoC6cPKWzkXvs7XEbN8srrBHBp4iKdflmzJgxkqS1a9fmWm+xWJSdnX3jVcGhVnXtkWv5w7s6yHfpIu08e0Z3edfQ1tPxOpaWql/u7ytbhQqSpAV3dVD1TyK04eQJ3V3D97rj3ucfmGv5pWYt9f7+ffr5zGnVq1zlmv4JFy8qIeOixtatJxerVff5BWh/cpIkadupeP2acFpvtr6jBI4YAHIL/lvfXMv+Pe7V72//S+mnTsnV7/LvuPMn4uTXtbNuq+EjSfJu21qnt/+qC/GnVCmP+bDuwbVzLddod6cSdu3WhbiTqlj12qkkWRfSlZWeLq+mYXKyWuVep7Yunj0rSUo7fkLn4+Pl26XTDR+v2RTryk9OTs51XwSfW1PypUuSpCrOLpKkjOxsWSQ5/++yqyS5lLPKyWLR1lPxhRozOydHnx+O1vmsTLWudv1fElVdXORTsZLWxR3XhaxM/fdUvBpW9lRmTrYe37ZZ77Ztp3I8VRzAXyAnI0OSVM7Fxb7utpo1lLT/gLLS02UYhpL27ZeRnSU3f79CjWnk5Chp337lZGaqUs0a1+1jrVRRVtfblHrkqHIyM3U+9rgqVqsqIztbsWt/kP89XWTh92CRMXEH+coxDD3981a1reat+v+7OtOqWnXdZi2vqTt+0svNWsowpGd//VnZhqGTFy7kO97viWfV7tsVupidLdfy5fV5p3t0u0fl6/a1WCz6pGNnTfxlmyb8vFX3+vopPCRUb+yJVHufGnIpV04dvl2hhIsX9ejtDfRovQYlfvwAYBiGjv+wUbfVrJHr6kxgr/t09OtV+u2tf0pOTnKyWlXrgV5yrnz932lXpJ85o6jFS5WTlaVyFSqo1gP3q6KX53X7WiwW1ep1n078sFHHf9ggW1AteTZsoFM//SI3fz9ZypVT1JKlykpPV9WmTVS1WZMSPfZbVbHCT2Zmpt5++21t2rRJCQkJuT7ra+vWrSVWHBzviW1btO9cov7TvZd9XVWXivq0Y2c9vm2L3t33u5wsFg0IClYTTy85WSz5jhfi7qFfevVTyqVL+vLoYY3avEHru9+fZwC6o7qPtvbsY1+OSj6nJdFR+qVXP929eqUeq9dA9/j6q+mKz3WXt48aVrn+LxAAKK7ja3/QxTMJqjN4YK71Jzf/V9kZGQoe0E/lKlVUclS0jn69SnUGD1DFqlXzHM+5ShXVHTFU2RmXdO5AlGK+/U7BgwbkGYBcfX0VOvz/Pz7qYmKiEvfuU2j4UB38dJmqNmsqW1At7f8oQq5+vqpYLe9947JiXSsbN26cFi5cqLvvvlu7d+/WwIEDde7cOXXt2rXQYzzxxBMKDAyUxWJRZGSkfX1gYKBCQ0MVFhamsLAwLVu2zN528OBBtW3bViEhIWrRooX27t1bqDYUz5PbtmhN7DF9f29P+d7mmqutS00/7e/3oI4/OExxDw7XwnadFHfhvGq55T/5uEK5cgq2uaupV1W90ryVGlbx1Nt7fyt0TY9t3axZLdsoxzAUmZigvrWCVK1iRd3lXUM/xp8s1nECQF5i1/2g5EOHFPzg31TB9v+/3zKSzilhZ6T8u90jt8AAVapWTT53tlVF7+o6szMy3zGdypWTc+XKquRdXTXa3yWXalV1ZsfOwtf0/XrV7NheMgylnzqtynVDVP62SnL181NabGxxD9VUihV+vvrqK61evVpPPPGErFarnnjiCa1YsUIbNmwo9Bj9+vXTli1bFBAQcE3bsmXLFBkZqcjISA0YMMC+fsyYMRo9erSioqI0adIkhYeHF6oNRWMYhp7ctkUrY47ou3t7qpZb3u8i8HKpKA9nZ22IO6HT6enXTGouzL4u5RRurtjCqP2q7Oysnv6Byv7f1cbMnBz7f7ONnCLtGwDyYhjG5eATFa3ggX+Ts4d7rvacrMvv+rL86Wq3xWKR8nnXax47k1HIObNnd/+mci4ucq8TbL/rYvzv96CRky0jp4j7NqlihZ/09HT5+l6e7V6xYkWdP39eISEh2rVrV6HHaNeunX2Mwjh9+rR27Nhh/+T4vn37KjY2VtHR0fm2oeie+GmLlh4+qI/b3y238uUVf+GC4i9cUHpWlr3Pxwf36+fTp3QoJVmfHorSoI3r9ET9RrmeBXTPd9/on/t+ty8/t+NnbY6P09HUVP2eeFbP7fhZm+LjNDCoToE1nU5P18zdOzX3f+/uquzsrLruHnp772/66XS8NsSdUNtq3iX3TQBgasfX/aCkvX8ooGd3latQQZlp55WZdl45/3vkh0uVKnKu7KGY79fpfNxJZSSd06lfdij16DG51wm2j3Pws3/rzK///7cxbtNmpcUeV0ZystLPnLm8HBOryvXqFlhT5vkLit/2k/w6X353l9XFRS6eVXR6+686fyJOqcdidJtvzRL+TtyaijXnp169evr555/VunVrNW/eXM8//7xsNptq1iyZb/qwYcNkGIZatmyp1157TVWrVlVsbKx8fHzsD1e0WCzy9/dXTEyM3N3d82wLDg7Ob1fKyMhQxv9m8UtSSkpKiRzDzez9/fskSV3WfJNr/Qd3dtCwOqGSpKjkZD3/6y9KzMhQgKubJjVqqifrN8zV/0hqis5mXLQvn7mYroc2b9DJCxfkXqGCGlT21KquPdS5ZsEheMLP/9W4+o1Uo9Jt9nUf3tVRD23eoHf/+F3jGzZW86rVin3MAHC1hF27JUnRSz/Ptd6/+z3ybNhAlnLlFNSvj+I2bdbh5SuUk3lJFTwqK6BHN7nXDrL3v5R0Tlnp6fblzPMXdGzVGmWeP69yzhXkUrWqav+tr2y1Agus6fgP/1G1Fs1V3u3/pyH4d79Xx779Tmd+3aVqLVvoNh/+J7AwihV+3nrrLZX739uc58yZo0ceeUSpqal6//33b7igH3/8Uf7+/srMzNRzzz2n4cOHa/Xq1Tc8bl5mzpyp6dOnl9r4N6OMEWMK7PNq81Z6tXmrfPtE9R+ca3n+nR2KXdPiDp2vWdeiajXt6TPgOr0B4MY0mTShwD4uVSor6IH78+1T/5GHcy0HdL+n2DXVuv++a9bdVsNH9R4eUewxzapY4adZs2b2r+vUqaP169eXWEH+/pc/6qB8+fIaN26cQkIuPybcz89PJ0+eVFZWlqxWqwzDUExMjPz9/WWz2fJsK8iUKVM0fvx4+3JKSor8/Ar3jAYAAHDzKVb4+fHHH/Nsa9euXbGLOX/+vDIzM+Xh4SFJWrp0qZo0ufzMgmrVqqlp06ZasmSJwsPDtXz5cvn6+tpva+XXlh9nZ2c5OzsXu2YAAHBzKVb4ufodWJKUmJgowzDk5eWluLi4Qo0xZswYffvtt4qPj9c999wjNzc3rV27Vn379lV2drYMw1BQUJAWLVpk32b+/PkKDw/XjBkzZLPZtHDhwkK1AQAAXFGs8HPyZO7nqWRmZuqFF1647tvW8zJ//vzrrs/vHWOhoaHatm1bkdsAAACuKJEPBClfvrxeeuklvfzyyyUxHAAAQKkpsU9D2717tzL/9/wDAACAsqpYt73atGmT66mWFy5c0P79+/XKK6+UWGEAAACloVjhZ+zYsbmWXV1d1bhx40K9uwoAAMCRihx+UlNTFRsbq++//15nzpxR1apV1bFjxxt6izsAAMBfpUjh59SpU7rzzjtVoUIF9evXTz4+Pjp58qS++OILffTRR9q0aZPS09O1bds2PfzwwwUPCAAA8BcrUviZMmWK2rRpo48//jjXnJ9p06Zp2LBhGjBggGJiYvThhx+WeKEAAAAloUjh59tvv9Xu3btzBR/p8geJzpo1S76+vlq5cqXuu+/azx8BAAAoC4r0Vve0tDR5eXldt61q1apycXEh+AAAgDKtSOEnJCREa9euvW7b2rVr7R9CCgAAUFYVKfxMmDBBI0aM0L///W9lZ2dLkrKzs/X5559r5MiRevrpp0ulSAAAgJJSpDk/Q4YM0dmzZ/XQQw9p8ODB8vLyUkJCglxcXDR9+nQNGTKktOoEAAAoEUV+zs+TTz6pkSNHatu2bUpISJCXl5fatGkjNze30qgPAACgRBXrCc9ubm7q2rVrSdcCAABQ6krsg00BAABuBoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKg4LP0888YQCAwNlsVgUGRlpX3/w4EG1bdtWISEhatGihfbu3XvDbQAAAFc4LPz069dPW7ZsUUBAQK71Y8aM0ejRoxUVFaVJkyYpPDz8htsAAACucFj4adeunXx9fXOtO336tHbs2KEhQ4ZIkvr27avY2FhFR0cXuw0AAOBqVkcXcLXY2Fj5+PjIar1clsVikb+/v2JiYuTu7l6stuDg4Hz3mZGRoYyMDPtySkpKKR0dAAAoC0w/4XnmzJlyd3e3v/z8/BxdEgAAKEVlKvz4+fnp5MmTysrKkiQZhqGYmBj5+/sXu60gU6ZMUXJysv0VGxtbegcIAAAcrkyFn2rVqqlp06ZasmSJJGn58uXy9fVVcHBwsdsK4uzsLJvNlusFAABuXQ6b8zNmzBh9++23io+P1z333CM3NzdFR0dr/vz5Cg8P14wZM2Sz2bRw4UL7NsVtAwAAuMJh4Wf+/PnXXR8aGqpt27aVaBsAAMAVZeq2FwAAQGkj/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMh/AAAAFMpk+EnMDBQoaGhCgsLU1hYmJYtWyZJOnjwoNq2bauQkBC1aNFCe/futW+TXxsAAMAVZTL8SNKyZcsUGRmpyMhIDRgwQJI0ZswYjR49WlFRUZo0aZLCw8Pt/fNrAwAAuKLMhp8/O336tHbs2KEhQ4ZIkvr27avY2FhFR0fn21aQjIwMpaSk5HoBAIBbV5kNP8OGDVPDhg310EMP6cyZM4qNjZWPj4+sVqskyWKxyN/fXzExMfm2FWTmzJlyd3e3v/z8/Er1uAAAgGOVyfDz448/as+ePdq5c6e8vLw0fPjwUtvXlClTlJycbH/FxsaW2r4AAIDjWR1dwPX4+/tLksqXL69x48YpJCREfn5+OnnypLKysmS1WmUYhmJiYuTv7y+bzZZnW0GcnZ3l7Oxc2ocEAADKiDJ35ef8+fM6d+6cfXnp0qVq0qSJqlWrpqZNm2rJkiWSpOXLl8vX11fBwcH5tgEAAFytzF35OXXqlPr27avs7GwZhqGgoCAtWrRIkjR//nyFh4drxowZstlsWrhwoX27/NoAAACuKHPhJygoSLt27bpuW2hoqLZt21bkNgAAgCvK3G0vAACA0kT4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApnJLhZ+DBw+qbdu2CgkJUYsWLbR3715HlwQAAMqYWyr8jBkzRqNHj1ZUVJQmTZqk8PBwR5cEAADKmFsm/Jw+fVo7duzQkCFDJEl9+/ZVbGysoqOjHVwZAAAoS6yOLqCkxMbGysfHR1br5UOyWCzy9/dXTEyMgoOD89wuIyNDGRkZ9uXk5GRJUkpKSonXmJaWpsMpyUrLzCzxsXFziE2/oKC0tFI5vwojLS1NUVGHdf78BYfsH4534kS8XFxqOPQcvJSYpHKXLjlk/3C87LTzSiuF34NXxjMMo8C+t0z4Ka6ZM2dq+vTp16z38/NzQDUwhe9XOboCAHCoZp9/UWpjp6amyt3dPd8+FqMwEekmcPr0aQUHBysxMVFWq1WGYcjHx0dbtmwp0pWfnJwcJSYmytPTUxaL5a8o3TRSUlLk5+en2NhY2Ww2R5cDE+IchKNxDpYewzCUmpqqGjVqyMkp/1k9t8yVn2rVqqlp06ZasmSJwsPDtXz5cvn6+uYbfCTJ2dlZzs7OudZ5eHiUYqWw2Wz8o4dDcQ7C0TgHS0dBV3yuuGXCjyTNnz9f4eHhmjFjhmw2mxYuXOjokgAAQBlzS4Wf0NBQbdu2zdFlAACAMuyWeas7yj5nZ2e9+OKL19xmBP4qnINwNM7BsuGWmfAMAABQGFz5AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4AQAApkL4QS6BgYGqW7eusrKy7OuaN2+ujRs3lsr+IiIitH//fvvyypUr9dRTT5XKvnDzKo3zcsWKFfrpp5+KvX2HDh20YsWKYm+Pm0dgYKBCQ0MVFhamevXq6d133y3yGHFxcbrrrrvsy9OmTdPFixftyy+88II++eSTEqkXBSP84BoZGRlasGDBX7KvP4ef+++/X3Pnzv1L9o2bS0mflwWFn6uDFrBs2TJFRkZqzZo1mjp1qvbs2VOk7WvUqKHNmzfbl6dPn54r/Lz00ksaPHhwidWL/BF+cI1p06bp5Zdf1oULF3KtT01N1cMPP6yWLVuqUaNGGj16tC5duiRJ2r9/v9q0aaP69eurT58+6tq1qyIiIiRJn376qVq1aqUmTZqocePG+uabbyRJH374oXbs2KGnnnpKYWFhWr16tSIiItS7d29JUpcuXfTFF1/Y979x40Y1adKkwFpwayrOefnnqzP9+vVTRESEVq9erZUrV+qNN95QWFiYPvzwQ23cuFH169fXQw89pLCwMH311Vd5nrswr4CAAIWGhmr//v3q06ePGjZsqAYNGmj+/PmSpJycHD322GO6/fbb1bhxYzVr1kwXL17U0aNH7R+aPXbsWEnSXXfdpbCwMJ0+fVrh4eGaN2+eLly4IE9PT8XHx9v3OW3aNPsV8YMHD6pHjx5q0aKFGjVqpHfeeeev/QbcKgzgKgEBAcauXbuMIUOGGK+88ophGIbRrFkzY8OGDcbDDz9sfPzxx4ZhGEZOTo7x0EMPGa+//rphGIbRvHlz46OPPjIMwzD27dtnODs7GwsXLjQMwzASEhKMnJwcwzAM48iRI0b16tWNixcvGoZhGO3btze++uor+/4XLlxo9OrVyzAMw/jkk0+MHj162NuGDRtmvPXWW4ZhGPnWgltPcc/LP59fffv2tZ+Xw4cPN+bOnWtv27Bhg2GxWIyNGzfa1xXl3MWt68r5ZxiGsWfPHsPNzc3o06ePMXnyZMMwDOPUqVOGr6+vsW3bNmPnzp1G3bp1jezsbMMwDOPcuXNGdna2ceTIEcPd3d0+piQjKSnJvnz1+fjwww8bb7zxhmEYl8/pwMBAY8+ePUZWVpbRrFkz448//jAMwzDOnz9vNGzY0Pjll19K9xtwC7qlPtgUJefll19Wy5Yt7f+HIl2+TbBt2zbNmTNHkpSenq5y5copJSVFkZGRGjZsmCTp9ttv15133mnf7siRIxo8eLCOHz8uq9WqxMREHTlyRHXr1s23hgceeEBPPPGETp48KTc3N61atcq+77xqwa2tKOdlcQQFBal9+/b25eKeu7j1DBgwQBUrVlSlSpX00UcfacyYMfrHP/4hSapWrZr69Omj9evX6/HHH1dWVpZGjhypjh07qkePHnJyKtpNlhEjRmjUqFF6+umntXHjRnl6eqphw4bat2+f9u7dq4EDB9r7pqamat++fWrRokWJHu+tjvCD6woMDNSgQYP0yiuv2NcZhqHly5crJCQkV9+UlJRrtrdYLPavBw4cqNdee039+vWTJFWpUiXXve68VKxYUf3799fixYtVtWpVderUSZ6envnWgltbUc5LSbJarcrOzrYvF3Teubq65lou7rmLW8+yZcsUFhZmXx4zZkyu9iu/89zd3fX7779r06ZN2rBhg6ZMmaIff/xRVmvh/9y2adNGOTk5+uWXXxQREaERI0ZIunyuV6lSRZGRkTd8PGbHnB/k6bnnntOSJUsUFxcnSerdu7dmzZplnwialJSk6Oho2Ww2NW7cWEuWLJEkHThwQFu2bLGPk5SUpFq1akmSlixZoqSkJHubzWZTcnJynjWMGDFCCxcuVEREhEaOHGlfn1ctuPUV9ryUpODgYP3888+SLl/Fufq8LOjcuzJWXucuzK1z58764IMPJElnzpzRl19+qS5duujMmTM6f/68unbtqhkzZigwMFD79u27Zns3N7cCf/e9/fbb+vbbbzVo0CBJUmhoqGw2mxYuXGjvFx0drcTExBI+ulsf4Qd58vLyst92kqS5c+eqYsWKCgsLU6NGjXT33Xfr6NGjkqRFixbpX//6lxo0aKBJkyapRYsW9sl9b775pvr166cmTZpo165d8vf3t+9j9OjRmjFjhn3C85+1bNlS5cqVU3R0tLp27Wpfn18tuLUV5bx85plntGHDBjVs2FBTpkxRq1at7OMMHTpUn3/+uZo0aaIPP/zwuvvK79yFub311lv6448/1LBhQ3Xs2FHPPvusWrVqpdjYWHXp0kWNGjVSgwYN1KBBA3Xr1u2a7SdMmKAuXbrYJzz/2dChQ/XZZ5+pc+fOqly5sqTLVzJXrVqlL7/8Uo0aNbJP0E9PTy/1473VWAzDMBxdBG5+aWlpuu2222SxWHTkyBG1adNG27dvl5+fn6NLAwAgF+b8oERs3bpVEydOlCRlZ2dr7ty5BB8AQJnElR8AAGAqzPkBAACmQvgBAACmQvgBAACmQvgBAACmQvgBcEuJiIhQ69ati739J598ok6dOpVgRQDKGsIPgDKrQ4cOcnFxkaurqzw9PXXvvffqwIEDpbrPwYMH6z//+Y992WKxaP/+/aW6TwB/LcIPgDJt3rx5SktL07Fjx1S5cmWFh4eX2r6ufEQGgFsb4QfATcHV1VVDhgzRb7/9pqioKHXp0kWVK1dWSEiIFixYkOd248ePl7+/v9zc3NS0aVNt2rTJ3jZt2jT16dNHI0eOlIeHh954441ct83atm0rSWrWrJlcXV31/vvvq2fPnnr99ddz7aNbt26aPXt2KRw1gNJA+AFwU0hJSdHixYvVsGFD3XfffWrTpo1OnTqlTz/9VJMmTdL69euvu12zZs20c+dOJSUladiwYerfv78uXLhgb//mm2/UtWtXJSYmaty4cbm23bp1qyTp119/VVpamkaPHq0RI0Zo8eLF9j7x8fHasGGDhgwZUvIHDaBUEH4AlGnjx49X5cqVVbduXWVkZOj1119XUlKSXnzxRVWoUEHNmzfXqFGj9PHHH193+8GDB8vLy0tWq1Xjxo1TZmam/vjjD3t7s2bNNHDgQDk5OalixYoF1tOzZ0/Fx8dr586dki5PkL777rvl7e1dMgcMoNQRfgCUaXPmzFFSUpLi4uL01VdfKS4uTr6+vipXrpy9T2BgoE6cOHHd7WfPnq3bb79d7u7u8vDwUHJyshISEuztAQEBRaqnfPnyGjx4sBYtWiRJWrRokYYPH16MIwPgKIQfADeVmjVr6vjx48rOzravO3r0qGrWrHlN382bN2vmzJlatmyZkpKSdO7cObm7u+vqjzS0WCxFrmHEiBFaunSpfv31V8XExKhXr17FOxgADkH4AXBTadWqlTw8PPTyyy/r0qVL2rlzpxYsWKChQ4de0zc1NVVWq1VeXl7KysrSq6++qpSUlCLtr3r16jp06FCudY0bN1bNmjU1cuRIDRw4UM7Ozjd0TAD+WoQfADeV8uXL65tvvtHmzZtVrVo1DRgwQK+++qq6du16Td977rlHPXr0UN26dRUQEKDy5cvLz8+vSPubPn26Ro0aJQ8PD33wwQf29SNGjNCePXu45QXchCzG1dd/AQCFsnLlSk2cOLHUH7oIoORx5QcAiujixYt6++23NXbsWEeXAqAYCD8AUAQ//PCDPD09ZRiGHnnkEUeXA6AYuO0FAABMhSs/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVP4PNNz8i2jW3VsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neutral, negative, positive = data['Polarity'].value_counts()\n",
    "\n",
    "plt.style.use('seaborn-paper')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(x='Negative', height = negative, color='#F96167', edgecolor='#201E20')\n",
    "ax.text(x ='Negative' , y=1500, s='{perc:.1f} %'.format(perc= negative / (negative + neutral + positive)*100), horizontalalignment='center')\n",
    "\n",
    "ax.bar(x='Neutral', height = neutral, color='#E7E8D1', edgecolor='#201E20')\n",
    "ax.text(x = 'Neutral', y=2500, s='{perc:.1f} %'.format(perc= neutral / (negative + neutral + positive)*100), horizontalalignment='center')\n",
    "\n",
    "ax.bar(x='Positive', height = positive, color='#317773', edgecolor='#201E20')\n",
    "ax.text(x = 'Positive', y=1500, s='{perc:.1f} %'.format(perc= positive / (negative + neutral + positive)*100), horizontalalignment='center')\n",
    "\n",
    "ax.set(xlabel='Polarity', \n",
    "       ylabel='Quantity',\n",
    "       title='Distribution of the polarity classes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Text data contains a lot of noise which makes the sentiment analysis task hard to complete. <br>\n",
    "Therefore I'm defining a couple of functions, which can be tuned as hyperparameter of the model, that help to get rid of some noise.\n",
    "\n",
    "\n",
    "#### Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/timo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/timo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/timo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/timo/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text column after removing punctation:\n",
      "0       no  i still see the wrong twins     https   gi...\n",
      "1                                                reverted\n",
      "2       you can leave a queue while in queue    before...\n",
      "3               didn t look at spelltargetrestrictions xd\n",
      "4       not sure about what kind of line lengths the p...\n",
      "                              ...                        \n",
      "7117    yeah  i m capable of working around it   a set...\n",
      "7118    looks fine to me   on jul 8  2013  at 10 12 pm...\n",
      "7119    formula updated to address this  would be nice...\n",
      "7120                                          i trust you\n",
      "7121    got it  thanks   on sat  mar 31  2012 at 2 07 ...\n",
      "Name: Text, Length: 7122, dtype: object\n",
      "\n",
      "The text column after removing stopwords:\n",
      "0       still see wrong twins https github com mojombo...\n",
      "1                                                reverted\n",
      "2                      leave queue queue needconfirmation\n",
      "3                         look spelltargetrestrictions xd\n",
      "4       sure kind line lengths project adheres diff sh...\n",
      "                              ...                        \n",
      "7117    yeah capable working around setting disables s...\n",
      "7118    looks fine jul 8 2013 10 12 pm joshua peek not...\n",
      "7119    formula updated address would nice brew audit ...\n",
      "7120                                                trust\n",
      "7121    got thanks sat mar 31 2012 2 07 jack nagel rep...\n",
      "Name: Text, Length: 7122, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # Removes special characters\n",
    "    regular_punct = list(string.punctuation)\n",
    "    for punc in regular_punct:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, ' ')\n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Removes the most common english words, like 'a', 'the', etc.\n",
    "    en_stops = set(stopwords.words('english'))\n",
    "    text = text.split()\n",
    "    text = \" \".join([word for word in text if not word in en_stops])  \n",
    "    return text\n",
    "\n",
    "prcsd_data = data.copy(deep=True)\n",
    "\n",
    "print('The text column after removing punctation:')\n",
    "prcsd_data['Text'] = prcsd_data['Text'].apply(remove_punctuation)\n",
    "print(prcsd_data['Text'])\n",
    "print()\n",
    "\n",
    "print('The text column after removing stopwords:')\n",
    "prcsd_data['Text'] = prcsd_data['Text'].apply(remove_stopwords)\n",
    "print(prcsd_data['Text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text column after tokenizing:\n",
      "0       [still, see, wrong, twins, https, github, com,...\n",
      "1                                              [reverted]\n",
      "2                 [leave, queue, queue, needconfirmation]\n",
      "3                     [look, spelltargetrestrictions, xd]\n",
      "4       [sure, kind, line, lengths, project, adheres, ...\n",
      "                              ...                        \n",
      "7117    [yeah, capable, working, around, setting, disa...\n",
      "7118    [looks, fine, jul, 8, 2013, 10, 12, pm, joshua...\n",
      "7119    [formula, updated, address, would, nice, brew,...\n",
      "7120                                              [trust]\n",
      "7121    [got, thanks, sat, mar, 31, 2012, 2, 07, jack,...\n",
      "Name: Text, Length: 7122, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# I'm using the tokenizer included in the nltk package\n",
    "print('The text column after tokenizing:')\n",
    "prcsd_data['Text'] = prcsd_data['Text'].apply(word_tokenize)\n",
    "print(prcsd_data['Text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text column after lemmatizing:\n",
      "0       [still, see, wrong, twin, http, github, com, m...\n",
      "1                                              [reverted]\n",
      "2                 [leave, queue, queue, needconfirmation]\n",
      "3                     [look, spelltargetrestrictions, xd]\n",
      "4       [sure, kind, line, length, project, adheres, d...\n",
      "                              ...                        \n",
      "7117    [yeah, capable, working, around, setting, disa...\n",
      "7118    [look, fine, jul, 8, 2013, 10, 12, pm, joshua,...\n",
      "7119    [formula, updated, address, would, nice, brew,...\n",
      "7120                                              [trust]\n",
      "7121    [got, thanks, sat, mar, 31, 2012, 2, 07, jack,...\n",
      "Name: Text, Length: 7122, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def lemmatizer(text):\n",
    "    lemma = WordNetLemmatizer()\n",
    "    return [lemma.lemmatize(w) for w in text]\n",
    "\n",
    "print('The text column after lemmatizing:')\n",
    "prcsd_data['Text'] = prcsd_data['Text'].apply(lemmatizer)\n",
    "print(prcsd_data['Text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Bag of Words\u001b[39;00m\n\u001b[1;32m      9\u001b[0m bow \u001b[39m=\u001b[39m CountVectorizer(ngram_range\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m X_bow \u001b[39m=\u001b[39m bow\u001b[39m.\u001b[39;49mfit_transform(prcsd_data[\u001b[39m'\u001b[39;49m\u001b[39mText\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mtolist())\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m     12\u001b[0m \u001b[39m# Bigram BoW\u001b[39;00m\n\u001b[1;32m     13\u001b[0m bbow \u001b[39m=\u001b[39m CountVectorizer(ngram_range\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1323\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1324\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1325\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1326\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1327\u001b[0m             )\n\u001b[1;32m   1328\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1330\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1333\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[1;32m   1200\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1201\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1202\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m         doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m         doc \u001b[39m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:71\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39mapply to a document.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m    preprocessed string\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[0;32m---> 71\u001b[0m     doc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39;49mlower()\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m accent_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     doc \u001b[39m=\u001b[39m accent_function(doc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def combine_text(input):\n",
    "    combined = ' '.join(input)\n",
    "    return combined\n",
    "\n",
    "# Bag of Words\n",
    "bow = CountVectorizer(ngram_range=(1, 1))\n",
    "X_bow = bow.fit_transform(prcsd_data['Text'].values.tolist()).toarray()\n",
    "\n",
    "# Bigram BoW\n",
    "bbow = CountVectorizer(ngram_range=(2, 2))\n",
    "X_bbow = bbow.fit_transform(prcsd_data['Text'].values.tolist())\n",
    "\n",
    "# Term-Frequency-Inverse-Document-Frequency\n",
    "tfidf = TfidfVectorizer(use_idf = True, ngram_range=(1, 1))\n",
    "X_tfidf = tfidf.fit_transform(prcsd_data['Text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prcsd_data['Text'].values.tolist())\n",
    "print(data['Text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bow.get_feature_names_out()))\n",
    "\n",
    "print(len(bbow.get_feature_names_out()))\n",
    "\n",
    "print(len(tfidf.get_feature_names_out()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different data with different preprocessing techniques\n",
    "\n",
    "data2 = data.copy(deep=True)\n",
    "data2['Text'] = data2['Text'].apply(remove_punctuation)\n",
    "data2['Text'] = data2['Text'].apply(remove_stopwords)\n",
    "\n",
    "data3 = data.copy(deep=True)\n",
    "data3['Text'] = data3['Text'].apply(remove_punctuation)\n",
    "data3['Text'] = data3['Text'].apply(word_tokenize)\n",
    "data3['Text'] = data3['Text'].apply(combine_text)\n",
    "\n",
    "data4 = data.copy(deep=True)\n",
    "data4['Text'] = data4['Text'].apply(remove_punctuation)\n",
    "data4['Text'] = data4['Text'].apply(word_tokenize)\n",
    "data4['Text'] = data4['Text'].apply(lemmatizer)\n",
    "data4['Text'] = data4['Text'].apply(combine_text)\n",
    "\n",
    "# Vectorize each dataset\n",
    "# Bag of Words\n",
    "bow0 = CountVectorizer(ngram_range=(1, 1))\n",
    "X_bow0 = bow0.fit_transform(data['Text'].values.tolist())\n",
    "\n",
    "bow2 = CountVectorizer(ngram_range=(1, 1))\n",
    "X_bow2 = bow2.fit_transform(data2['Text'].values.tolist())\n",
    "\n",
    "bow3 = CountVectorizer(ngram_range=(1, 1))\n",
    "X_bow3 = bow3.fit_transform(data3['Text'].values.tolist())\n",
    "\n",
    "bow4 = CountVectorizer(ngram_range=(1, 1))\n",
    "X_bow4 = bow4.fit_transform(data4['Text'].values.tolist())\n",
    "\n",
    "# Bigram BoW\n",
    "bbow0 = CountVectorizer(ngram_range=(2, 2))\n",
    "X_bbo0 = bbow0.fit_transform(data['Text'].values.tolist())\n",
    "\n",
    "bbow2 = CountVectorizer(ngram_range=(2, 2))\n",
    "X_bbo2 = bbow2.fit_transform(data2['Text'].values.tolist())\n",
    "\n",
    "bbow3 = CountVectorizer(ngram_range=(2, 2))\n",
    "X_bbo3 = bbow3.fit_transform(data3['Text'].values.tolist())\n",
    "\n",
    "bbow4 = CountVectorizer(ngram_range=(2, 2))\n",
    "X_bbo4 = bbow4.fit_transform(data4['Text'].values.tolist())\n",
    "\n",
    "# Term-Frequency-Inverse-Document-Frequency\n",
    "tfidf0 = TfidfVectorizer(use_idf = True, ngram_range=(1, 1))\n",
    "X_tfidf0 = tfidf0.fit_transform(data['Text'].values.tolist())\n",
    "\n",
    "tfidf2 = TfidfVectorizer(use_idf = True, ngram_range=(1, 1))\n",
    "X_tfidf2 = tfidf2.fit_transform(data2['Text'].values.tolist())\n",
    "\n",
    "tfidf3 = TfidfVectorizer(use_idf = True, ngram_range=(1, 1))\n",
    "X_tfidf3 = tfidf3.fit_transform(data3['Text'].values.tolist())\n",
    "\n",
    "tfidf4 = TfidfVectorizer(use_idf = True, ngram_range=(1, 1))\n",
    "X_tfidf4 = tfidf4.fit_transform(data4['Text'].values.tolist())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the features\n",
    "In the first bar, no preprocessing is performed at all. That bar is just an object of comparison.\n",
    "In the other cases, text is always converted to lower case and special characters are also always removed, because that's best practice in almost every NLP task.\n",
    "Let's plot how the other preprocessing tasks influence the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_raw = len(bow0.get_feature_names_out())\n",
    "features_tokenize = len(bow3.get_feature_names_out())\n",
    "features_stopwords = len(bow2.get_feature_names_out())\n",
    "features_lemmatize = len(bow4.get_feature_names_out())\n",
    "features_all = len(bow.get_feature_names_out())\n",
    "\n",
    "plt.style.use('seaborn-paper')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(x='Raw data', height = features_raw, color='#317773', edgecolor='#201E20')\n",
    "ax.text(x ='Raw data' , y=6000, s=str(features_raw), horizontalalignment='center')\n",
    "\n",
    "ax.bar(x='Tokenize', height = features_tokenize, color='#317773', edgecolor='#201E20')\n",
    "ax.text(x = 'Tokenize', y=6000, s=str(features_tokenize), horizontalalignment='center')\n",
    "\n",
    "ax.bar(x='Remove stopwords', height = features_stopwords, color='#317773', edgecolor='#201E20')\n",
    "ax.text(x = 'Remove stopwords', y=6000, s=str(features_stopwords), horizontalalignment='center')\n",
    "\n",
    "ax.bar(x='Lemmatize', height = features_lemmatize, color='#317773', edgecolor='#201E20')\n",
    "ax.text(x = 'Lemmatize', y=6000, s=str(features_lemmatize), horizontalalignment='center')\n",
    "\n",
    "ax.bar(x='All previous', height = features_all, color='#317773', edgecolor='#201E20')\n",
    "ax.text(x = 'All previous', y=6000, s=str(features_all), horizontalalignment='center')\n",
    "\n",
    "ax.set(xlabel='Preprocessing task', \n",
    "       ylabel='Features Quantity',\n",
    "       title='Distribution of features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X = X_tfidf.todense() # Just tfidf, because training time is otherweise too long on my local pc.\n",
    "Y = prcsd_data['Polarity'].map({'negative': -1, 'neutral': 0, 'positive': 1})\n",
    "\n",
    "print(type(X))\n",
    "print('X_train shape:', X.shape)\n",
    "print()\n",
    "print(type(Y))\n",
    "print('Y_test shape:', Y.shape)\n",
    "\n",
    "X\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Model\n",
    "Now let's train a deep learning model, using the different hyperparameters, and let's evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_bow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m# not used atm\u001b[39;00m\n\u001b[1;32m      9\u001b[0m text_vectorizer \u001b[39m=\u001b[39m TextVectorization(max_tokens\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \n\u001b[1;32m     10\u001b[0m                                     \u001b[39m#already done\u001b[39;00m\n\u001b[1;32m     11\u001b[0m                                     standardize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m                                     output_sequence_length\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                                     )\n\u001b[0;32m---> 21\u001b[0m X \u001b[39m=\u001b[39m X_bow \u001b[39m# Just tfidf, because training time is otherweise too long on my local pc.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m Y \u001b[39m=\u001b[39m prcsd_data[\u001b[39m'\u001b[39m\u001b[39mPolarity\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap({\u001b[39m'\u001b[39m\u001b[39mnegative\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneutral\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpositive\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m})\n\u001b[1;32m     24\u001b[0m prcsd_data[\u001b[39m'\u001b[39m\u001b[39mPolarity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m prcsd_data[\u001b[39m'\u001b[39m\u001b[39mPolarity\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap({\u001b[39m'\u001b[39m\u001b[39mnegative\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneutral\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpositive\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_bow' is not defined"
     ]
    }
   ],
   "source": [
    "# Other hyperparameters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, GRU\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# not used atm\n",
    "text_vectorizer = TextVectorization(max_tokens=None, \n",
    "                                    #already done\n",
    "                                    standardize=None,\n",
    "                                    #whitespace delimiter\n",
    "                                    split=\"whitespace\", \n",
    "                                    #dont group anything, every token alone\n",
    "                                    ngrams = None, \n",
    "                                    output_mode =\"int\",\n",
    "                                    #length of each sentence == length of largest sentence\n",
    "                                    output_sequence_length=None\n",
    "                                    )\n",
    "\n",
    "X = X_bow # Just tfidf, because training time is otherweise too long on my local pc.\n",
    "Y = prcsd_data['Polarity'].map({'negative': -1, 'neutral': 0, 'positive': 1})\n",
    "\n",
    "prcsd_data['Polarity'] = prcsd_data['Polarity'].map({'negative': -1, 'neutral': 0, 'positive': 1})\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
    "\n",
    "Y_train = to_categorical(Y_train, 3)\n",
    "Y_test = to_categorical(Y_test, 3)\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(text_vectorizer)\n",
    "model.add(Embedding(input_dim=100, output_dim=300, input_length=11320))\n",
    "model.add(GRU(128, dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(X_train[:10])\n",
    "print()\n",
    "print(type(X_test))\n",
    "print(X_test[:10])\n",
    "print()\n",
    "print(type(Y_train))\n",
    "print(Y_train[:10])\n",
    "print()\n",
    "print(type(Y_test))\n",
    "print(Y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model and predicting the sentiment\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=256, epochs=5)\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "accuracies = [0.7222, 0.8763, 0.9275, 0.9276, 0.9279]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot([1, 2, 3, 4, 5], accuracies)\n",
    "\n",
    "ax.set(xlabel='Epoch', \n",
    "       ylabel='Accuracy',\n",
    "       title='Accuracy per Epoch')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
